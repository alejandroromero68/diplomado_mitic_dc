{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:\n",
      "   A    B    C\n",
      "0  1  2.0  NaN\n",
      "1  3  NaN  6.0\n",
      "2  7  8.0  9.0\n",
      "nDatos imputados:\n",
      "     A    B    C\n",
      "0  1.0  2.0  7.5\n",
      "1  3.0  5.0  6.0\n",
      "2  7.0  8.0  9.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "\n",
    "# Datos con valores faltantes\n",
    "X = pd.DataFrame({\n",
    "    'A': [1, 3, 7],\n",
    "    'B': [2, None, 8],\n",
    "    'C': [None, 6, 9]\n",
    "})\n",
    "\n",
    "print(\"Datos originales:\")\n",
    "print(X)\n",
    "\n",
    "# Crear un imputador con la estrategia de la media\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Ajustar y transformar los datos\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Convertir el resultado a un DataFrame de pandas\n",
    "X_imputed_df = pd.DataFrame(X_imputed, columns=X.columns)\n",
    "\n",
    "print(\"nDatos imputados:\")\n",
    "print(X_imputed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Datos categóricos\n",
    "X = [['rojo'], ['verde'], ['azul'], ['verde'], ['rojo']]\n",
    "\n",
    "# Crear un codificador One-Hot\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Ajustar y transformar los datos\n",
    "X_encoded = encoder.fit_transform(X)\n",
    "\n",
    "print(X_encoded.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 0 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Datos categóricos\n",
    "y = ['rojo', 'verde', 'azul', 'verde', 'rojo']\n",
    "\n",
    "# Crear un codificador de etiquetas\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Ajustar y transformar los datos\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "print(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.9305555555555556\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "X, y = fetch_openml('tic-tac-toe', version=1, return_X_y=True)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear un imputador para manejar valores faltantes\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Crear un codificador One-Hot para variables categóricas\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Preprocesar los datos de entrenamiento\n",
    "X_train_imputed = imputer.fit_transform(X_train)\n",
    "X_train_encoded = encoder.fit_transform(X_train_imputed)\n",
    "\n",
    "# Preprocesar los datos de prueba\n",
    "X_test_imputed = imputer.transform(X_test)\n",
    "X_test_encoded = encoder.transform(X_test_imputed)\n",
    "\n",
    "# Codificar las etiquetas de destino\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "# Crear y entrenar un clasificador de árboles de decisión\n",
    "classifier = DecisionTreeClassifier()\n",
    "classifier.fit(X_train_encoded, y_train_encoded)\n",
    "\n",
    "# Hacer predicciones en el conjunto de prueba\n",
    "y_pred = classifier.predict(X_test_encoded)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjunto de entrenamiento transformado: (16512, 8)\n",
      "Conjunto de prueba transformado: (4128, 8)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el conjunto de datos de California Housing\n",
    "data = fetch_california_housing(as_frame=True)\n",
    "df = data.frame\n",
    "\n",
    "# Separar en características (X) y variable objetivo (y)\n",
    "X = df.drop(\"MedHouseVal\", axis=1)\n",
    "y = df[\"MedHouseVal\"]\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Crear el preprocesador con selección automática de columnas numéricas y pasar el resto\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), X.select_dtypes(include=['float64', 'int']).columns),\n",
    "        (\"cat\", OneHotEncoder(), X.select_dtypes(include=['object']).columns)\n",
    "    ],\n",
    "    remainder='passthrough',  # Pasar las columnas no transformadas sin cambios\n",
    "    n_jobs=-1,                # Usar todos los núcleos disponibles para procesamiento\n",
    "    verbose=True,             # Mostrar información de procesamiento\n",
    "    sparse_threshold=0.3      # Convertir a formato disperso si la densidad es menor al umbral\n",
    ")\n",
    "\n",
    "# Aplicar las transformaciones al conjunto de entrenamiento y prueba\n",
    "X_train = preprocessor.fit_transform(X_train)\n",
    "X_test = preprocessor.transform(X_test)\n",
    "\n",
    "# Mostrar información sobre el conjunto de datos transformado\n",
    "print(\"Conjunto de entrenamiento transformado:\", X_train.shape)\n",
    "print(\"Conjunto de prueba transformado:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_transformed = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.34476576,  0.98214266,  0.62855945, ..., -0.04959654,\n",
       "         1.05254828, -1.32783522],\n",
       "       [ 2.33223796, -0.60701891,  0.32704136, ..., -0.09251223,\n",
       "         1.04318455, -1.32284391],\n",
       "       [ 1.7826994 ,  1.85618152,  1.15562047, ..., -0.02584253,\n",
       "         1.03850269, -1.33282653],\n",
       "       ...,\n",
       "       [-1.14259331, -0.92485123, -0.09031802, ..., -0.0717345 ,\n",
       "         1.77823747, -0.8237132 ],\n",
       "       [-1.05458292, -0.84539315, -0.04021111, ..., -0.09122515,\n",
       "         1.77823747, -0.87362627],\n",
       "       [-0.78012947, -1.00430931, -0.07044252, ..., -0.04368215,\n",
       "         1.75014627, -0.83369581]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp_mitic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
